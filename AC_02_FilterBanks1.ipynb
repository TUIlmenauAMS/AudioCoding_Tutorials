{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xB6LH3F1L1jc"
      },
      "source": [
        "<center>\n",
        "    <img src=\"https://raw.githubusercontent.com/TUIlmenauAMS/AudioCoding_Tutorials/main/images/ac_header.png\">\n",
        "</center>\n",
        "\n",
        "### <a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://www.tu-ilmenau.de/mt-ams/personen/schuller-gerald/\">Prof. Dr. -Ing. Gerald Schuller</a> <br> <a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://www.tu-ilmenau.de/mt-ams/lehre/msp-and-adsp-tutorials/\">Jupyter Notebook: Renato Profeta</a>\n",
        "\n",
        "[Applied Media Systems Group](https://www.tu-ilmenau.de/en/applied-media-systems-group/) <br>\n",
        "[Technische Universität Ilmenau](https://www.tu-ilmenau.de/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wi0-owR7L1jd"
      },
      "source": [
        "# Filter Banks I"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "hide_input": true,
        "id": "FbOYNhKfL1jd",
        "outputId": "80764ddf-9358-48d4-e059-5014124f39e2"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/Zk8Oum6LtUc?rel=0\" frameborder=\"0\" allow=\"accelerometer; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "%%html\n",
        "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/Zk8Oum6LtUc?rel=0\" frameborder=\"0\" allow=\"accelerometer; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hide_input": false,
        "id": "2qDIZtiJL1jd"
      },
      "source": [
        "<center>\n",
        "    <img src='https://raw.githubusercontent.com/TUIlmenauAMS/AudioCoding_Tutorials/main/images/ac_02_audioCoders.png' width='900'>\n",
        "</center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ZXKfoU4L1jd"
      },
      "source": [
        "## Filter Banks\n",
        "- essential element of most audio coders.\n",
        "- transform from time to frequency domain and vice-versa.\n",
        "<br>\n",
        "\n",
        "    - Goal:\n",
        "        - Good filter bank.\n",
        "        - Compress audio signals.\n",
        "    - Approach:\n",
        "        - Redundancy Reduction.\n",
        "        - Irrelevance Reduction."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5htrgQyEL1jd"
      },
      "source": [
        "## Filtering = Convolution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yoC-ybuyL1jd"
      },
      "source": [
        "   - Remember, a digital (bandpass) filter can be represented by the **convolution** of the audio signal x(n) with the impulse response of the filter h(n), with non-zero coefficients between N=0,...L-1. The output y(n) is then obtained by the convolution formula:\n",
        "\n",
        "$$\\large\n",
        "y(n)=x(n)*h(n)=\\sum_{n'=0}^{L-1} x(n-n')\\cdot h(n') $$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hide_input": false,
        "id": "8m5jR13DL1jd"
      },
      "source": [
        "## Downsampled Convolution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tysrS0LvL1jd"
      },
      "source": [
        " - We downsample the filtered (convolved) signal by N by keeping only every N'th sample. We replace n by mN in our convolution equation. n' is the convolution sum index at the higher sampling rate,\n",
        "\n",
        " $$\\large\n",
        " y^{\\downarrow N}(m)=y(mN)=\\sum_{n'=0}^{L-1} x(mN-n')\\cdot h(n')\n",
        " $$\n",
        "\n",
        " - To symplify our notation, we always define *m* as the index at the lower sampling rate:\n",
        "\n",
        " $$\\large\n",
        " y(m) := y^{\\downarrow N}(m) $$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pGoWpFmbL1je"
      },
      "source": [
        "## Upsampling Followed by Convolution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hide_input": false,
        "id": "HREpS7f4L1je"
      },
      "source": [
        "  - For the synthesis filter bank we first have upsampling, followed by bandbass filtering/ convolution.\n",
        "  - The upsampled version contains the samples of the downsampled version at every N'th sample (and zeros in between), $y^{\\uparrow N}(mN)=y(m)$.\n",
        "  - The convolution of the upsampled version is then:\n",
        "  $$\\large\n",
        "  \\hat{y}(n):= \\sum_{n'=0}^{L-1} y^{\\uparrow N}(n-n')\\cdot g_k(n') $$\n",
        "  - The upsampled version of y is only non-zero for when its argument is multiples of N, n-n'=m'N , hence n'=n-M'N, m' is the convolution sum index at the lower sampling rate:\n",
        "  $$\\large\n",
        "  \\hat{y}(n):=\\sum_{m'} y^{\\uparrow N} (m' N) \\cdot g_k(n-m'N)$$\n",
        "  - For the summation limits for *m* we need to observe that $g_k$ is only non-zero for the argument in the range of 0,…,L-1, hence:\n",
        "  $$\\large\n",
        "  0 \\leq n-m' \\leq L-1 \\\\\n",
        "  \\large\n",
        "  0 \\geq -n+m'N \\geq -L+1, \\quad n \\geq m'N \\geq n-L+1, \\quad \\frac{n}{N} \\geq m' \\geq \\frac{(n-L+1)}{N} $$\n",
        "  - With $\\lfloor  . \\rfloor$ the floor operator (rounding down), and $\\lceil . \\rceil$ the ceiling operator (rounding up):\n",
        "  $$\\large\n",
        "  \\left\\lfloor \\frac{n}{N} \\right\\rfloor \\geq m' \\geq \\left\\lceil \\frac{(n-L+1)}{N} \\right\\rceil$$\n",
        "  and with $y^{\\uparrow N}(m'N)=y(m)$ we get:\n",
        "  \n",
        "  $$\\large\n",
        "  \\hat{y}(n):=\\sum_{m'=\\left\\lceil\\frac{(n-L+1}{N}\\right\\rceil}^{\\left\\lceil\\frac{n}{N}\\right\\rceil}\n",
        "  y(m') \\cdot g_k(n-m'N)$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5GUMzncyL1je"
      },
      "source": [
        "## Critically sampled Analysis and Synthesis Filter Bank, Direct Implementation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HqKJbdG4L1je"
      },
      "source": [
        "<center>\n",
        "    <img src='https://raw.githubusercontent.com/TUIlmenauAMS/AudioCoding_Tutorials/main/images/ac_03_critc1.png' width='900'>\n",
        "</center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I7W12TEYL1je"
      },
      "source": [
        "<center>\n",
        "    <img src='https://raw.githubusercontent.com/TUIlmenauAMS/AudioCoding_Tutorials/main/images/ac_04_critc2.png' width='900'>\n",
        "</center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hide_input": false,
        "id": "aAUYYby5L1je"
      },
      "source": [
        "## Down-Sampling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ati_p3ZIL1je"
      },
      "source": [
        "- The operation of \"down-sampling\" by factor N describes the process of keeping every Nth sample discarding the rest:\n",
        "\n",
        "<center>\n",
        "    <img src='https://raw.githubusercontent.com/TUIlmenauAMS/AudioCoding_Tutorials/main/images/ac_05_downsamplint.png' width='900'>\n",
        "</center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "scrolled": true,
        "id": "s_TnP36LL1je"
      },
      "source": [
        "## Up-Sampling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "scrolled": false,
        "id": "2arlJyWZL1je"
      },
      "source": [
        " - The operation of \"up-sampling\" by factor N describes the insertion of N-1 zeros between every sample of the input:\n",
        "\n",
        "<center>\n",
        "    <img src='https://raw.githubusercontent.com/TUIlmenauAMS/AudioCoding_Tutorials/main/images/ac_06_upsampling.png' width='900'>\n",
        "</center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aVKJHl8aL1je"
      },
      "source": [
        "## Filter Bank Structure - The Analysis Filter Bank Direct Implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "hide_input": true,
        "id": "d2N1uKjeL1je",
        "outputId": "2bc4af91-ed41-4879-a63a-4740fb3d403f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/To2nyZJfbmw?rel=0\" frameborder=\"0\" allow=\"accelerometer; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "%%html\n",
        "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/To2nyZJfbmw?rel=0\" frameborder=\"0\" allow=\"accelerometer; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mw50ffLSL1je"
      },
      "source": [
        "<center>\n",
        "    <img src='https://raw.githubusercontent.com/TUIlmenauAMS/AudioCoding_Tutorials/main/images/ac_07_analysis.png' width='300'>\n",
        "</center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zha1nHqNL1je"
      },
      "source": [
        "**Example:**\n",
        "\n",
        " - N=1024 filters (power of 2 for efficient FFT impl.)\n",
        " - $f_s$=44100Hz sampling frequency\n",
        " - $f_g$=22050Hz Nyquist frequency\n",
        "$$\\large\n",
        "\\frac{f_g}{N}=\\frac{\\frac{f_s}{2}}{N}=21.5 Hz $$\n",
        " - If we have N filters, and no down-samplers, then we would have N*fs samples per second after filtering – more than input!\n",
        "     - hence down-samplers.\n",
        "     - with down-samplers: number of samples stays constant, **downsampling factor = number of subbands**.\n",
        "     - This means \"critical sampling\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZbJcuc9pL1je"
      },
      "source": [
        "## Filter Bank Structure - The Synthesis Filter Bank, Direct Implementation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7wDeaPR5L1je"
      },
      "source": [
        "<center>\n",
        "    <img src='https://raw.githubusercontent.com/TUIlmenauAMS/AudioCoding_Tutorials/main/images/ac_08_synthesis.png' width='400'>\n",
        "</center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "scrolled": false,
        "id": "-1NqJxz_L1je"
      },
      "source": [
        " - Up-sample each subband by N to restore original sampling rate.\n",
        " - Apply passband filter to each subband signal.\n",
        " - Add each subband signal to generate output signal."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uxN1OpSNL1je"
      },
      "source": [
        "## Filter Bank Structure - Direct Implementation: Python Example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "hide_input": true,
        "id": "uxjsj0CML1je",
        "outputId": "177c01db-c869-4afb-ca16-adc813413772"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/TW8-RRnLIQs?rel=0\" frameborder=\"0\" allow=\"accelerometer; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "%%html\n",
        "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/TW8-RRnLIQs?rel=0\" frameborder=\"0\" allow=\"accelerometer; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "scrolled": false,
        "id": "W964QW-5L1je"
      },
      "source": [
        "Implement 1 branch, subband k=1, of the analysis and synthesis filter bank with N=8 subbands with 32kHz sampling rate (hence the passband is between 2 kHz and 4 kHz), in **direct implementation.**\n",
        "\n",
        "Start with designing a bandpass filter using the scipy.signal.remez function, which is an \"equi-ripple\" FIR filter design function:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cF1sRmEnL1je"
      },
      "outputs": [],
      "source": [
        "import scipy.signal as signal\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "hide_input": false,
        "id": "KCl74yxFL1je"
      },
      "outputs": [],
      "source": [
        "N=8\n",
        "b=signal.remez(8*N,[0,500,1000,2000,2500,16000],[0,1,0],\n",
        "[100,1,100],Hz=32000, type='bandpass')\n",
        "#Check the design:\n",
        "plt.figure(figsize=(10,8))\n",
        "plt.plot(b)\n",
        "plt.title('Filter Impulse Response: Bandpass k=1, N=8')\n",
        "plt.xlabel('Time in Samples')\n",
        "plt.grid()\n",
        "\n",
        "w,H=signal.freqz(b)\n",
        "plt.figure(figsize=(10,8))\n",
        "plt.plot(w,20*np.log10(abs(H)+1e-6))\n",
        "plt.title('Filter Magnitude Frequency Response: Bandpass k=1, N=8')\n",
        "plt.xlabel('Normalized Frequency')\n",
        "plt.ylabel('dB')\n",
        "plt.grid()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bKbabOsLL1jf"
      },
      "source": [
        "Now the analysis filtering and down sampling:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_XcA5e2jL1jf"
      },
      "outputs": [],
      "source": [
        "import librosa\n",
        "import IPython.display as ipd\n",
        "import scipy.signal as signal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "hide_input": false,
        "id": "XdumFn13L1jf"
      },
      "outputs": [],
      "source": [
        "sr=32000\n",
        "x, sr = librosa.load('audio/Doug Aldrich - Midnight Sun [Electrovision 1997].mp3', sr=sr)\n",
        "ipd.Audio(x,rate=sr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RvEe3-0YL1jf"
      },
      "outputs": [],
      "source": [
        "print(\"length of sound in samples: \", len(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6eSun36jL1jf"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,8))\n",
        "plt.title('Original Signal')\n",
        "#Filter implementation:\n",
        "filtered=signal.lfilter(b,1,x)\n",
        "print(\"length of filtered sound in samples: \", len(filtered))\n",
        "plt.plot(filtered)\n",
        "plt.grid()\n",
        "#play filtered sound:\n",
        "display(ipd.Audio(filtered*30,rate=32000))\n",
        "#Now Down-sampling with factor N:\n",
        "N=8\n",
        "filteredds=filtered[::N]\n",
        "plt.figure(figsize=(10,8))\n",
        "plt.plot(filteredds)\n",
        "plt.grid()\n",
        "display(ipd.Audio(filteredds*30,rate=4000))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KWIl3R8dL1jf"
      },
      "source": [
        "Now the up-sampling and synthesis filtering:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k7yd-1yBL1jf"
      },
      "outputs": [],
      "source": [
        "#Up-sampling:\n",
        "filteredus=np.zeros(len(filteredds)*N)\n",
        "filteredus[::N]=filteredds\n",
        "#Listen to the up-sampled sound:\n",
        "display(ipd.Audio(filteredus,rate=32000))\n",
        "#Synthesis Filtering:\n",
        "#Bandpass Synthesis Filter implementation to attenuate the spectral copies:\n",
        "filteredsyn=signal.lfilter(b,1,filteredus)\n",
        "plt.figure(figsize=(10,8))\n",
        "plt.plot(filteredsyn)\n",
        "plt.title('Up-sampled and Filtered Signal')\n",
        "plt.xlabel('Time in Samples')\n",
        "plt.ylabel('Sample Values')\n",
        "plt.grid()\n",
        "display(ipd.Audio(filteredsyn,rate=32000))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lEqt1nE4L1jf"
      },
      "source": [
        "**Observe:** After the synthesis fltering the signal again sounds like after the analysis fltering, even though we had downsampling and up-sampling in between. This means we did not loose much information after down-sampling!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nGVtEXdwL1jf"
      },
      "source": [
        "## Definition: Perfect Reconstruction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "hide_input": true,
        "id": "dIKVu2VaL1jm",
        "outputId": "6e2a834d-05e6-4d37-b654-8c77973c07fb"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/De6Q7ArcrWA?rel=0\" frameborder=\"0\" allow=\"accelerometer; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "%%html\n",
        "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/De6Q7ArcrWA?rel=0\" frameborder=\"0\" allow=\"accelerometer; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zXMy9oOQL1jn"
      },
      "source": [
        " - The property of the output signal out of cascaded analysis and synthesis filter bank being identical to the input signal (except for a time shift $n_d$ ) is called **\"Perfect Reconstruction\"** (PR):\n",
        " $$ \\text{output}=x(n-n_d)$$ <br>\n",
        " - A filter bank having this property is called a \"Perfect Reconstruction Filter Bank\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5B8kfHuOL1jn"
      },
      "source": [
        "## Filter Bank Structure – Perfect Reconstruction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FSuanvmyL1jn"
      },
      "source": [
        "### Example PR filter bank: DFT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PLOl3F0iL1jn"
      },
      "source": [
        "<center>\n",
        "    <img src='https://raw.githubusercontent.com/TUIlmenauAMS/AudioCoding_Tutorials/main/images/ac_09_fb.png' width='400'>\n",
        "</center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hide_input": false,
        "id": "UZ_z4xTKL1jn"
      },
      "source": [
        " - Thought experiment: ideal `brick wall filters`.\n",
        " - Brick wall: magnitude in passband is one, otherwise zero.\n",
        " - Nyquist Theorem: we can down-sample the subband signals by factor N without loss of information.\n",
        " - With suitable brick wall synthesis filters, perfect reconstruction (input = output) could be achieved.\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RMnr8bHwL1jn"
      },
      "source": [
        "### Bandpass Nyquist"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jSJSx2miL1jn"
      },
      "source": [
        "Goal:\n",
        "\n",
        " - Keep critical downsampling (downsampling rate N is equal to number of subbands).\n",
        " - No increase in number of samples.\n",
        " - Still want to obtain perfect reconstruction!\n",
        " - Ideally aliasing cancels!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JfEc2YWPL1jn"
      },
      "source": [
        "#### Example Bandpass Signal"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hide_input": true,
        "id": "IWvhDfwcL1jn"
      },
      "source": [
        "<center>\n",
        "    <img src='https://raw.githubusercontent.com/TUIlmenauAMS/AudioCoding_Tutorials/main/images/ac_10_bandpass_ny.png' width='400'>\n",
        "</center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "befjRvAoL1jn"
      },
      "source": [
        "### After Downsampling and Upsampling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-OmnHscFL1jn"
      },
      "source": [
        "**Bandpass Nyquist:**\n",
        "\n",
        "Sampling at least twice the bandwidth f_b enables the reconstruction of the bandwidth limited signal (if the lower end of the freq. band is multiple integers of the bandwidth).\n",
        "\n",
        "<center>\n",
        "    <img src='https://raw.githubusercontent.com/TUIlmenauAMS/AudioCoding_Tutorials/main/images/ac_11_bandpass_ny2.png' width='600'>\n",
        "</center>\n",
        "\n",
        "**Reconstruction:** apply ideal bandpass filter for original frequency range (\"fish out\" original), no overlap with aliasing.\n",
        "\n",
        "**Problem:** ideal bandpass filters are not realizable!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W5VQ_FlRL1jn"
      },
      "source": [
        "## Ideal Filters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "806L5Wq9L1jn"
      },
      "source": [
        " - Ideal filters are not realizable.\n",
        " - In the time domain they would mean a convolution of our signal with a Sinc function.\n",
        " - Sinc function is infinitely long and not causal, meaning it causes infinite delay.\n",
        " - We can not simply use a DFT or FFT to obtain an ideal filter in the frequency domain either.\n",
        " - Because the DFT also represents a filter bank, but a special type.\n",
        " - Its equivalent filters are far from perfect filters (hence we cannot make ideal filters with it), not good enough for our purposes (audio coding and the ear), as we will see.\n",
        " - Don‘t use your eye (looking at waveforms) to guess what the ear might be hearing (quite different processing)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-61FZRejL1jn"
      },
      "source": [
        "## Basic Principle: z-Transformation (1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "hide_input": true,
        "id": "h6bbiHPdL1jn",
        "outputId": "39181a15-e072-4467-e6f0-3b4f6c9e9abc"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/FfZrIimlciA?rel=0\" frameborder=\"0\" allow=\"accelerometer; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "%%html\n",
        "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/FfZrIimlciA?rel=0\" frameborder=\"0\" allow=\"accelerometer; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hide_input": true,
        "id": "XIKHCaAgL1jn"
      },
      "source": [
        " - **Goal:** Realizable FB with critical sampling and perfect reconstruction (PR).\n",
        " - **Problems** with ideal flter banks:\n",
        "   - Brick wall filters not realizable (infinite delay!)\n",
        " - **Approach:**\n",
        "   - Find a suitable mathematical description for realizable Perfect Reconstruction Filter Banks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VxSwV9ucL1jn"
      },
      "source": [
        "### Analysis Side"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qnNP4kTDL1jn"
      },
      "source": [
        "Use **Noble Identities** to Exchange Filtering and Downsampling of Each Subband.\n",
        "\n",
        "Take one subband:\n",
        "\n",
        "<center>\n",
        "    <img src='https://raw.githubusercontent.com/TUIlmenauAMS/AudioCoding_Tutorials/main/images/ac_12_noble.png' width='600'>\n",
        "     <img src='https://raw.githubusercontent.com/TUIlmenauAMS/AudioCoding_Tutorials/main/images/ac_13_noble2.png' width='600'>\n",
        "</center>\n",
        "\n",
        "*See also:* https://github.com/GuitarsAI/ADSP_Tutorials/blob/master/ADSP_08_Nobel%20Identities.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "hide_input": true,
        "id": "GjgROkKHL1jn",
        "outputId": "0af5ee4b-abb6-4d34-9844-017e5b5ecbf5"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<iframe width=\"900\" height=\"400\" src=\"https://nbviewer.jupyter.org/github/GuitarsAI/ADSP_Tutorials/blob/master/ADSP_08_Nobel%20Identities.ipynb\"></iframe>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "%%html\n",
        "<iframe width=\"900\" height=\"400\" src=\"https://nbviewer.jupyter.org/github/GuitarsAI/ADSP_Tutorials/blob/master/ADSP_08_Nobel%20Identities.ipynb\"></iframe>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "scrolled": false,
        "id": "KFx6MbcXL1jn"
      },
      "source": [
        "#### Noble Identities, Polyphase Vectors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hide_input": false,
        "id": "_rzPbOMTL1jn"
      },
      "source": [
        "The left hand side with the downsamplers can be seen as a serial to parallel converter into blocks of length N. We obtain blocks or vectors of length N for the signal x and the filter H, each containing the \"polyphase\" components.\n",
        "\n",
        "The z-Transform vector of the polyphase components of input x:\n",
        "\n",
        "$$\\large\n",
        "X(z)=[X_0(z), \\dots, X_{N-1}(z)]$$\n",
        "\n",
        "The z-Transform vector of the polyphase components of the filter:\n",
        "\n",
        "$$\\large\n",
        "H_k(z) = [H_{N-1,k}(z), \\dots, H_{0,k}(z)]$$\n",
        "with\n",
        "\n",
        "$$\\large\n",
        "X_n(z)=\\sum_{m=0}^\\infty x(mN+n) \\cdot z^{-m} \\quad H_{n,k}(z)=\\sum_{m=0}^\\infty h_k(mN+n) \\cdot z^{-m} \\\\\n",
        "n=0,\\dots,N-1 $$\n",
        "\n",
        "This shows a representation as vector of polynomials. Observe that a polyphase vector like:\n",
        "\n",
        "$$\\large\n",
        "X(z)=[X_0(z), \\dots, X_{N-1}(z)]$$\n",
        "\n",
        "can alternatively also be written as a polynomial of vectors,\n",
        "\n",
        "$$\\large\n",
        "X(z) = \\sum_{m=0}^\\infty [x(mN), x(mN+1), \\dots x(nM+N-1)] \\cdot z^{-m} $$\n",
        "\n",
        "We see that the vectors in the sum are the blocks of length N of our audio signal. The sum takes all blocks of length N of our audio signal and turns them into this polyphase polynomial.\n",
        "\n",
        "The filtering and downsampling then becomes:\n",
        "\n",
        "$$\\large\n",
        "X(z) \\cdot H_k^T(z) = Y_k(z) $$\n",
        "\n",
        "Since we have not just 1 filter, but N filters, we can collect the N filter polyphase vectors of size N into a \"polyphase matrix\" of size NxN!. This then produces a polyphase vector of size N for the N resulting filter output or subbands:\n",
        "\n",
        "$$\\large\n",
        "Y(z)=[Y_0(z), \\cdot, Y_{N-1}(z)]$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "txR3LRtAL1jn"
      },
      "source": [
        "#### Polyphase Description"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-v6VsRhL1jn"
      },
      "source": [
        "Arrange the N impulse response vectors Hk(z) of length N into a NxN square matrix (can be invertible!):\n",
        "\n",
        "<center>\n",
        "    <img src='https://raw.githubusercontent.com/TUIlmenauAMS/AudioCoding_Tutorials/main/images/ac_14_poly1.png' width='600'>\n",
        "</center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M6ZDip3HL1jn"
      },
      "source": [
        "##### Polyphase Description, Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hide_input": true,
        "id": "G5OtnVCEL1jo"
      },
      "source": [
        " - Hence the form of the polyphase matrix for analysis is (Type 1 polyphase):\n",
        " <center>\n",
        "    <img src='https://raw.githubusercontent.com/TUIlmenauAMS/AudioCoding_Tutorials/main/images/ac_15_poly2.png' width='600'>\n",
        "</center>\n",
        "<br>\n",
        " - and each subband filter can hence be written as:\n",
        "  <center>\n",
        "    <img src='https://raw.githubusercontent.com/TUIlmenauAMS/AudioCoding_Tutorials/main/images/ac_16_poly3.png' width='400'>\n",
        "</center>\n",
        "\n",
        "Final equation of analysis filter bank: $\\large Y(z) = X(z) \\cdot H(z)$\n",
        "\n",
        " - H(z): Analysis Polyphase Matrix, NxN\n",
        " - X(z): Vector of polynomials, contains input samples.\n",
        "\n",
        "Mathematically very simple operation for entire filter bank <ins>including</ins> down sampling.\n",
        "\n",
        "  <center>\n",
        "    <img src='https://raw.githubusercontent.com/TUIlmenauAMS/AudioCoding_Tutorials/main/images/ac_17_polyA1.png' width='400'>\n",
        "</center>\n",
        "\n",
        "**Observe** that a multiplication with $z^{-1}$ can be interpreted as a delay of the signal by 1 sample. It can be implemented as a delay or memory element."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "hide_input": true,
        "id": "xi9y1yPLL1jo",
        "outputId": "a3d61b7c-291e-41d7-ba09-feec97a47965"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/kZxBuvAZvps?rel=0\" frameborder=\"0\" allow=\"accelerometer; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "%%html\n",
        "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/kZxBuvAZvps?rel=0\" frameborder=\"0\" allow=\"accelerometer; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9n_wINZKL1jo"
      },
      "source": [
        "**Example**:\n",
        "Assume a signal x=[5,6,7,8,9,10] and N=3. Then we get the signal blocks x(m) with m in a range as we needed to fit the signal, as:\n",
        " - x(0)=[5,6,7]\n",
        " - x(1)=[8,9,10]\n",
        "\n",
        "The polyphase elements $x_n(z)$ with phase n=0...,N-1 are:\n",
        "\n",
        "$$\\large\n",
        "X_0(z) = 5 + 8 \\cdot z^{-1} \\quad X_1(z) = 6 + 9 \\cdot z^{-1} \\quad X_2(z) = 7 + 10 \\cdot z^{-1}$$\n",
        "\n",
        "Or written as polynomial of blocks,\n",
        "\n",
        "$$\\large\n",
        "X(z) = \\sum_{m=0}^1 [5,6,7] \\cdot z^0 + [8,9,10] \\cdot z^{-1}$$\n",
        "\n",
        "The polyphase vector is $\\large X(z)=[X_0(z),X_1(z),X_2(z)]=[5 + 8 \\cdot z^{-1}, 6 + 9 \\cdot z^{-1},  7 + 10 \\cdot z^{-1}]$\n",
        "\n",
        "Assume we have the first analysis impulse response of $h_0$ =[3,4,5,6,7,8] for N=3.\n",
        "\n",
        "Then its polyphase vector is in general:\n",
        "\n",
        "$$\\large\n",
        "H_k(z) := [H_{N-1,k}(z), H_{N-2,k}(z), \\dots, H_{0,k}(z)]$$\n",
        "\n",
        "(with our phases going down) and for this example:\n",
        "$$\\large\n",
        "H_0(z)=[5 + 8 \\cdot z^{-1},4 + 7 \\cdot z^{-1}, 3 + 6 \\cdot z^{-1}]$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hide_input": true,
        "id": "CAppppSYL1jo"
      },
      "source": [
        "### Synthesis Side"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X5E7j27UL1jo"
      },
      "source": [
        "Use **Noble Identities** to Exchange Filtering and Upsampling of Each Subband.\n",
        "\n",
        "Take one subband:\n",
        "\n",
        "<center>\n",
        "    <img src='https://raw.githubusercontent.com/TUIlmenauAMS/AudioCoding_Tutorials/main/images/ac_18_polyS1.png' width='700'>\n",
        "     <img src='https://raw.githubusercontent.com/TUIlmenauAMS/AudioCoding_Tutorials/main/images/ac_19_polyS2.png' width='600'>\n",
        "</center>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6n2FL4UyL1jo"
      },
      "source": [
        "##### Polyphase Description, Synthesis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ezlz7bJqL1jo"
      },
      "source": [
        " - The polyphase matrix for synthesis is (Type 2 polyphase):\n",
        "  <center>\n",
        "    <img src='https://raw.githubusercontent.com/TUIlmenauAMS/AudioCoding_Tutorials/main/images/ac_20_synth.png' width='600'>\n",
        "</center>\n",
        "<br>\n",
        " - Now each filter has its polyphase components along the rows, and each subband filter can be written as:\n",
        "   <center>\n",
        "    <img src='https://raw.githubusercontent.com/TUIlmenauAMS/AudioCoding_Tutorials/main/images/ac_21_synth2.png' width='400'>\n",
        "</center>\n",
        "<br>\n",
        " - Output of synthesis Filter Bank:\n",
        "   <center>\n",
        "    <img src='https://raw.githubusercontent.com/TUIlmenauAMS/AudioCoding_Tutorials/main/images/ac_22_synth3.png' width='600'>\n",
        "</center>\n",
        "<br>\n",
        "\n",
        "Perfect recosntruction (PR) results if:\n",
        "\n",
        "$$\\large\n",
        "G(z) = z^{-d} \\cdot H(z) (z^{-d} = Delay)$$\n",
        "\n",
        "Since by substitution we get:\n",
        "$$\\large\n",
        "\\hat{X}(z)=X(z)\\cdot H(z) \\cdot z^{-d} \\cdot H^{-1}(z) \\\\\n",
        "\\large\n",
        "\\rightarrow \\hat{X}(z)=z^{-d} \\cdot X(z) $$\n",
        "\n",
        "*Observe:* PR requires 'only' a matrix inversion.\n",
        "\n",
        "**Problem: How to invert a matrix of polynomials?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L0FKTXkML1jo"
      },
      "source": [
        "### Example: Construction of H(z)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tr3kYuCkL1jo"
      },
      "source": [
        " - How to obtain a H(z), which only has the first coefficient of our polynomial unequal to zero?\n",
        "\n",
        " $\\large \\rightarrow$ design $h_k(n)$ such that $H_k(z)$ has no higher powers of z:\n",
        "\n",
        "<img src='https://raw.githubusercontent.com/TUIlmenauAMS/AudioCoding_Tutorials/main/images/ac_23_exH.png' width='400'>\n",
        "<br>\n",
        "Hence only the first block of our impulse response can be unequal to 0, and it is limited to a length of N! (too short!)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qjAnaRcGL1jo"
      },
      "source": [
        "### Examples: The DFT as a filter bank"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "hide_input": true,
        "id": "iVE1Q_uuL1jo",
        "outputId": "afaba791-88a4-49c1-ddcb-4e6d629901b4"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/5YIPZvZTtpQ?rel=0\" frameborder=\"0\" allow=\"accelerometer; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "%%html\n",
        "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/5YIPZvZTtpQ?rel=0\" frameborder=\"0\" allow=\"accelerometer; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ezmQjUZBL1jo"
      },
      "source": [
        "The Discrete Fourier Transform can be written as:\n",
        "\n",
        "$$\\large\n",
        "Y_k(m)=\\sum_{n=0}^{N-1} x(mN-N+1+n) \\cdot e^{-j \\frac{2\\pi}{N}kn}$$\n",
        "with the block index m=1...L\n",
        "\n",
        "The substitution n'=N-1-n yields:\n",
        "\n",
        "$$\\large\n",
        "Y_k(m)=\\sum_{n=0}^{N-1} x(mN-n') \\cdot e^{-j \\frac{2\\pi}{N}k(N-1-n')}$$\n",
        "\n",
        "This is a critically sampled filter bank with the impulse response (design trick: $h_k(n)$ is only as long as one block).\n",
        "<img src='https://raw.githubusercontent.com/TUIlmenauAMS/AudioCoding_Tutorials/main/images/ac_24_dft.png' width='600'>\n",
        "<br>\n",
        "\n",
        "**Convolution (blockwise)**\n",
        "$$\\large\n",
        "y_k(m)=\\sum_{n=0}^{N-1} x(mN-n) \\cdot h_k(n)$$\n",
        "\n",
        "The analysis polyphase matrix of the DFT is identical to the DFT transform matrix:\n",
        "\n",
        "$$H(z)=F=DFT-Matrix$$\n",
        "\n",
        "$\\large \\rightarrow$ Perfect reconstruction, but filters not good enough!\n",
        "\n",
        "The Fourier Matrix is defined as:\n",
        "\n",
        "$$\\large\n",
        "F_{n,k}=W^{nk}$$\n",
        "\n",
        "<img src='https://raw.githubusercontent.com/TUIlmenauAMS/AudioCoding_Tutorials/main/images/ac_25_dftMatrix.png' width='700'>\n",
        "<br>\n",
        "\n",
        "with $\\large W=e^{-j2 \\frac{\\pi}{N}}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WdHQjE7ML1jo"
      },
      "source": [
        "### Example: The $DCT_{IV}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kqkSy8atL1jo"
      },
      "source": [
        "Using the same substitution as with the DFT, the Discrete Cosine Transform type 4 can be written as:\n",
        "\n",
        "$$\\large\n",
        "Y_k(m)=\\sum_{n=0}^{N-1}x(mN-n) \\cdot \\cos \\left( \\frac{\\pi}{N} \\left(k+\\frac{1}{2}\\right) \\left((N-1-n)+\\frac{1}{2}\\right)\\right) \\quad n.k=0 \\dots N-1$$\n",
        "\n",
        "with impulse response (N: block length):\n",
        "\n",
        "$$\\large\n",
        "h_k(n)= \\cos \\left( \\frac{\\pi}{N} \\left( k+\\frac{1}{2} \\right) \\left( (N-1-n) + \\frac{1}{2} \\right) \\right) \\quad n.k=0 \\dots N-1$$\n",
        "\n",
        "Special property: filter bank is orthogonal:\n",
        "\n",
        "$$\\large\n",
        "\\frac{2}{N} H^T(z^{-1})=z^{-d} \\cdot H^{-1}(z) $$\n",
        "\n",
        "for Perfect Reconstruction, hence the synthesis is the transposed time reversed matrix."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vm_h8bX6L1jo"
      },
      "source": [
        "#### DCT Type 4, with 8 Subbands (N=8)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3fc9OcuPL1jo"
      },
      "source": [
        "<img src='https://raw.githubusercontent.com/TUIlmenauAMS/AudioCoding_Tutorials/main/images/ac_26_dct4.png' width='800'>\n",
        "<img src='https://raw.githubusercontent.com/TUIlmenauAMS/AudioCoding_Tutorials/main/images/ac_27_dct4_1.png' width='800'>\n",
        "<br>\n",
        "\n",
        "**Problem**\n",
        "\n",
        " - Except for the zeros, the stopband attenuation is not very high (still PR!)\n",
        " - Problem especially for audio, since the zeros are not sufficient for good selectivity.\n",
        " - Approach: design filter banks with longer filters, with better ability for higher stopband attenuation.\n",
        " - $\\rightarrow$ Really use z-domain for longer filters."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nTfmRqIhL1jo"
      },
      "source": [
        "### Python Examples\n",
        "\n",
        "*Real-time python audio examples: you need a microphone and speakers connected.* <br>\n",
        "*THESE EXAMPLES WILL NOT WORK ON REMOTE ENVIRONMENTS SUCH AS GOOGLE COLAB AND BINDER:*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "hide_input": true,
        "id": "7JoFB3fmL1jo",
        "outputId": "62d1c276-3a22-4a1b-995e-5bac556c5999"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/VpHtVs3aovU?rel=0\" frameborder=\"0\" allow=\"accelerometer; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "%%html\n",
        "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/VpHtVs3aovU?rel=0\" frameborder=\"0\" allow=\"accelerometer; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tLhEqZl7L1jo"
      },
      "source": [
        "#### FFT Example\n",
        "\n",
        "Real-time FFT of blocks of 1024 audio samples. Horizontally you seen the FFT bins or subbands, vertically the magnitude of the FFT coefficients/samples in dB.\n",
        "\n",
        "**Observe:** The FFT subbands are symmetric around the center, the highest frequency (Nyquist frequency) is in the center. If you whistle, you see 2 peaks at the corresponding FFT subbands."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hZPsVvUvL1jo"
      },
      "outputs": [],
      "source": [
        "# Imports and Configuration\n",
        "%matplotlib qt\n",
        "import pyaudio\n",
        "import numpy as np\n",
        "import scipy.signal as signal\n",
        "import struct\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.mlab import window_hanning,specgram\n",
        "from matplotlib.colors import LogNorm\n",
        "from matplotlib.ticker import FuncFormatter, MultipleLocator\n",
        "from ipywidgets import ToggleButton, Checkbox, Button\n",
        "from ipywidgets import HBox, interact\n",
        "import threading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NJNAOWhPL1jo"
      },
      "outputs": [],
      "source": [
        "CHUNK_SIZE = 2048 #Blocksize\n",
        "CHANNELS = 1 # Audio Channes\n",
        "RATE = 32000  #Sampling Rate in Hz\n",
        "N=8.0     #Downsampling/Upsampling Rate\n",
        "FORMAT = pyaudio.paInt16 #conversion format for PyAudio stream\n",
        "NFFT = 1024 #NFFT value for spectrogram\n",
        "OVERLAP = 512 #overlap value for spectrogram"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "prBvyl-rL1jo"
      },
      "outputs": [],
      "source": [
        "# Function to Plot Spetrogram\n",
        "ctr=0 # Control for plotting\n",
        "def run_fft(toggle_run):\n",
        "    global ctr\n",
        "    while(True):\n",
        "        if toggle_run.value==True:\n",
        "            break\n",
        "\n",
        "        #Reading from audio input stream into data with block length \"CHUNK\":\n",
        "        data_stream = stream.read(CHUNK_SIZE)\n",
        "        shorts = (struct.unpack( 'h' * CHUNK_SIZE, data_stream ));\n",
        "        samples=np.array(list(shorts),dtype=float);\n",
        "\n",
        "\n",
        "\n",
        "        #play out samples:\n",
        "        samples=np.clip(samples, -32000,32000)\n",
        "        samples=samples.astype(int)\n",
        "        #converting from short integers to a stream of bytes in \"data\":\n",
        "        data=struct.pack('h' * len(samples), *samples);\n",
        "        #Writing data back to audio output stream:\n",
        "        stream.write(data, CHUNK_SIZE)\n",
        "\n",
        "        # Update Plot\n",
        "        if (ctr%4 ==0):\n",
        "            line.set_ydata(20.0*np.log((np.abs(np.fft.fft(samples[0:fftlen])/np.sqrt(fftlen))+1))/np.log(10.0))\n",
        "            fig.canvas.draw()\n",
        "        ctr+=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z7PJGZ46L1jp"
      },
      "outputs": [],
      "source": [
        "# GUI\n",
        "toggle_run = ToggleButton(description='Stop')\n",
        "button_start= Button(description='Start')\n",
        "box_sampling = Checkbox(False, description='Downsampling/Upsampling')\n",
        "box_LPFilter = Checkbox(False, description='LP Filters')\n",
        "\n",
        "def start_button(button_start):\n",
        "    thread.start()\n",
        "    button_start.disabled=True\n",
        "button_start.on_click(start_button)\n",
        "\n",
        "\n",
        "def on_click_toggle_run(change):\n",
        "    if change['new']==False:\n",
        "        toggle_run.value==True\n",
        "        stream.stop_stream()\n",
        "        stream.close()\n",
        "        p.terminate()\n",
        "        plt.close()\n",
        "toggle_run.observe(on_click_toggle_run, 'value')\n",
        "\n",
        "\n",
        "\n",
        "box_buttons = HBox([button_start,toggle_run])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jAa8hXQvL1jp"
      },
      "outputs": [],
      "source": [
        "# Create a Thread for run_spectrogram function\n",
        "thread = threading.Thread(target=run_fft, args=(toggle_run,))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mqxUi2XUL1jp"
      },
      "outputs": [],
      "source": [
        "# Start Audio Stream\n",
        "# Create\n",
        "p = pyaudio.PyAudio()\n",
        "\n",
        "stream = p.open(format=FORMAT,\n",
        "                channels=CHANNELS,\n",
        "                rate=RATE,\n",
        "                input=True,\n",
        "                output=True,\n",
        "                frames_per_buffer=CHUNK_SIZE)\n",
        "\n",
        "\n",
        "\n",
        "input_data = stream.read(CHUNK_SIZE)\n",
        "samples = np.frombuffer(input_data,np.int16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sufng7d9L1jp"
      },
      "outputs": [],
      "source": [
        "# Initialize Plot and Display GUI\n",
        "\n",
        "display(box_buttons)\n",
        "\n",
        "fftlen=int(CHUNK_SIZE/2);\n",
        "\n",
        "[fig, ax] = plt.subplots()\n",
        "plt.ylabel('dB')\n",
        "plt.xlabel('FFT bins/Subbands')\n",
        "plt.title('Live FFT Magnitude Spectrum of Microphone Signal')\n",
        "\n",
        "x = np.arange(0, fftlen)        # x-array\n",
        "#Set scale on y-axis and generate line object with it:\n",
        "[line, ]= ax.plot(x, 100.0**np.sin(x))\n",
        "\n",
        "def handle_close(evt):\n",
        "    # When everything done, release the capture\n",
        "    stream.stop_stream()\n",
        "    stream.close()\n",
        "    p.terminate()\n",
        "\n",
        "plt.connect('close_event', handle_close);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qTtNvEMUL1jp"
      },
      "source": [
        "#### Spectrogram Example"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VYcckRD-L1jp"
      },
      "source": [
        "A time-frequency representation, a spectrogram, which shows the magnitude of the FFT coefficients as different colors.\n",
        "\n",
        "**Observe:** This shows the time-frequency nature of filter banks (of which the FFT is a special example). You have both, time and frequency dependencies."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "hide_input": true,
        "id": "t4hLVcIZL1jp",
        "outputId": "d07dc889-b19b-4929-80ec-2b7147d6a423"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/6WJQ3KCBN7w\" frameborder=\"0\" allow=\"accelerometer; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "%%html\n",
        "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/6WJQ3KCBN7w\" frameborder=\"0\" allow=\"accelerometer; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C_GtjFsgL1jp"
      },
      "outputs": [],
      "source": [
        "# Imports and Configuration\n",
        "\n",
        "import pyaudio\n",
        "import numpy as np\n",
        "import scipy.signal as signal\n",
        "import struct\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.mlab import window_hanning,specgram\n",
        "from matplotlib.colors import LogNorm\n",
        "from matplotlib.ticker import FuncFormatter, MultipleLocator\n",
        "from ipywidgets import ToggleButton, Checkbox, Button\n",
        "from ipywidgets import HBox, interact\n",
        "import threading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l742LiXlL1jp"
      },
      "outputs": [],
      "source": [
        "CHUNK_SIZE = 2048 #Blocksize\n",
        "CHANNELS = 1 # Audio Channes\n",
        "RATE = 32000  #Sampling Rate in Hz\n",
        "N=8.0     #Downsampling/Upsampling Rate\n",
        "FORMAT = pyaudio.paInt16 #conversion format for PyAudio stream\n",
        "NFFT = 1024 #NFFT value for spectrogram\n",
        "OVERLAP = 512 #overlap value for spectrogram"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ctwkwJNUL1jp"
      },
      "outputs": [],
      "source": [
        "# LP Filter\n",
        "[b,a]=signal.iirfilter(8, 1900.0/16000,rp=60,btype='lowpass')\n",
        "#Memory for the filter:\n",
        "zd=np.zeros(8)\n",
        "zu=np.zeros(8)\n",
        "LPFilterOn=False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DQdAbQG-L1jp"
      },
      "outputs": [],
      "source": [
        "# Function to Plot Spetrogram\n",
        "SamplingOn=False # Turn Donwsampling/Upsampling On/Off\n",
        "ctr=0 # Control for plotting\n",
        "def run_spectrogram(toggle_run):\n",
        "    global zd, zu, ctr, SamplingOn, LPFilterOn\n",
        "    while(True):\n",
        "        if toggle_run.value==True:\n",
        "            break\n",
        "\n",
        "        #Reading from audio input stream into data with block length \"CHUNK\":\n",
        "        data_stream = stream.read(CHUNK_SIZE)\n",
        "        shorts = (struct.unpack( 'h' * CHUNK_SIZE, data_stream ));\n",
        "        samples=np.array(list(shorts),dtype=float);\n",
        "\n",
        "        #start block-wise signal processing:\n",
        "        #Low pass filter *before downsampling*:\n",
        "        if LPFilterOn==True:\n",
        "            [samples,zd]=signal.lfilter(b, a, samples, zi=zd)\n",
        "\n",
        "        #Compute a block/an array of a unit pulse train corresponding a downsampling rate of N:\n",
        "        #make unit pulse train with modulus function \"%\":\n",
        "        s=(np.arange(0,CHUNK_SIZE)%N)==0\n",
        "        #The sampling:\n",
        "        #multiply the signal with the unit pulse train:\n",
        "        if SamplingOn == True:\n",
        "            samples=samples*s;\n",
        "\n",
        "\n",
        "        #Lowpass filtering *after upsampling*:\n",
        "        #filter function:\n",
        "        if LPFilterOn==True:\n",
        "            [samples,zu]=signal.lfilter(b, a, samples, zi=zu)\n",
        "\n",
        "        #end signal processing\n",
        "\n",
        "        #play out samples:\n",
        "        samples=np.clip(samples, -32000,32000)\n",
        "        samples=samples.astype(int)\n",
        "        #converting from short integers to a stream of bytes in \"data\":\n",
        "        data=struct.pack('h' * len(samples), *samples);\n",
        "        #Writing data back to audio output stream:\n",
        "        stream.write(data, CHUNK_SIZE)\n",
        "\n",
        "        # Update Plot\n",
        "        if (ctr%4 ==0):\n",
        "            arr2D,freqs,bins = specgram(samples,window=window_hanning,\n",
        "                                        Fs = RATE,NFFT=NFFT,noverlap=OVERLAP)\n",
        "            im_data = im.get_array()\n",
        "            if ctr < 16:\n",
        "                im_data = np.hstack((im_data,arr2D))\n",
        "                im.set_array(im_data)\n",
        "            else:\n",
        "                keep_block = arr2D.shape[1]*(16 - 1)\n",
        "                im_data = np.delete(im_data,np.s_[:-keep_block],1)\n",
        "                im_data = np.hstack((im_data,arr2D))\n",
        "                im.set_array(im_data)\n",
        "            fig.canvas.draw()\n",
        "        ctr+=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iYYlGc3UL1jp"
      },
      "outputs": [],
      "source": [
        "# GUI\n",
        "toggle_run = ToggleButton(description='Stop')\n",
        "button_start= Button(description='Start')\n",
        "box_sampling = Checkbox(False, description='Downsampling/Upsampling')\n",
        "box_LPFilter = Checkbox(False, description='LP Filters')\n",
        "\n",
        "def start_button(button_start):\n",
        "    thread.start()\n",
        "    button_start.disabled=True\n",
        "button_start.on_click(start_button)\n",
        "\n",
        "\n",
        "def on_click_toggle_run(change):\n",
        "    if change['new']==False:\n",
        "        stream.stop_stream()\n",
        "        stream.close()\n",
        "        p.terminate()\n",
        "        plt.close()\n",
        "toggle_run.observe(on_click_toggle_run, 'value')\n",
        "\n",
        "def box_samping_changed(box_sampling):\n",
        "    global SamplingOn\n",
        "    if box_sampling['new']:\n",
        "        SamplingOn=True\n",
        "    else:\n",
        "        SamplingOn=False\n",
        "box_sampling.observe(box_samping_changed, names='value')\n",
        "\n",
        "def box_LPFilter_changed(box_LPFilter):\n",
        "    global LPFilterOn\n",
        "    if box_LPFilter['new']:\n",
        "        LPFilterOn=True\n",
        "    else:\n",
        "        LPFilterOn=False\n",
        "box_LPFilter.observe(box_LPFilter_changed, names='value')\n",
        "\n",
        "box_buttons = HBox([button_start,toggle_run])\n",
        "box_checkbox = HBox([box_sampling,box_LPFilter])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xCwchw59L1jp"
      },
      "outputs": [],
      "source": [
        "# Create a Thread for run_spectrogram function\n",
        "thread = threading.Thread(target=run_spectrogram, args=(toggle_run,))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eN4E2_SlL1jp"
      },
      "outputs": [],
      "source": [
        "# Start Audio Stream\n",
        "# Create\n",
        "p = pyaudio.PyAudio()\n",
        "\n",
        "stream = p.open(format=FORMAT,\n",
        "                channels=CHANNELS,\n",
        "                rate=RATE,\n",
        "                input=True,\n",
        "                output=True,\n",
        "                frames_per_buffer=CHUNK_SIZE)\n",
        "\n",
        "\n",
        "\n",
        "input_data = stream.read(CHUNK_SIZE)\n",
        "samples = np.frombuffer(input_data,np.int16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eEplXmDWL1jp"
      },
      "outputs": [],
      "source": [
        "# Initialize Plot and Display GUI\n",
        "\n",
        "display(box_buttons)\n",
        "display(box_checkbox)\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "arr2D,freqs,bins = specgram(samples,window=window_hanning,\n",
        "                                Fs = RATE,NFFT=NFFT,noverlap=OVERLAP)\n",
        "\n",
        "\n",
        "extent = (bins[0],bins[-1]*32,freqs[-1],freqs[0])\n",
        "im = plt.imshow(arr2D,aspect='auto',extent = extent,interpolation=\"none\",\n",
        "                     norm = LogNorm(vmin=.01,vmax=1))\n",
        "plt.xlabel('Time')\n",
        "plt.ylabel('Frequency (Hz)')\n",
        "plt.title('Live Spectogram')\n",
        "plt.gca().invert_yaxis()\n",
        "plt.xticks([])\n",
        "\n",
        "def handle_close(evt):\n",
        "    # When everything done, release the capture\n",
        "    stream.stop_stream()\n",
        "    stream.close()\n",
        "    p.terminate()\n",
        "    plt.close()\n",
        "plt.connect('close_event', handle_close);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lxQnW2lrL1jp"
      },
      "source": [
        "#### MDCT Example"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HtHau7LTL1jp"
      },
      "source": [
        "An example for the so-called MDCT filter bank. You see a decomposition of the audio signal into MDCT subbands. These subbands can then be processed, for instance we set every subband except for a few to zero. Then we display the result as a spectrogram waterfall diagramm, and use the inverse/synthesis MDCT for reconstrution and play the resulting sound back.\n",
        "\n",
        "**Observe:** The MDCT does not have those symmetric 2 sides, it only has one side of the spectrum, with the lowest frequencies on the left side, and the hightest on the right. If we only keep a few subbands, it sounds muffled\n",
        "or „narrowband“."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "hide_input": true,
        "id": "mVGCLgtpL1jp",
        "outputId": "a970701c-1177-4399-ad08-97c67cf6cc77"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/4UWe3yQmWIs?rel=0\" frameborder=\"0\" allow=\"accelerometer; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "%%html\n",
        "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/4UWe3yQmWIs?rel=0\" frameborder=\"0\" allow=\"accelerometer; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JiUkmhpIL1jp"
      },
      "outputs": [],
      "source": [
        "# Imports and Configuration\n",
        "%matplotlib notebook\n",
        "\n",
        "import numpy as np\n",
        "import scipy.signal as signal\n",
        "import pyaudio\n",
        "import struct\n",
        "import scipy.fftpack as spfft\n",
        "from ipywidgets import ToggleButton, Button\n",
        "from ipywidgets import HBox\n",
        "import threading\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yx_3Rt3gL1jq"
      },
      "outputs": [],
      "source": [
        "# Signal Processing Parameters\n",
        "\n",
        "N=512                          # Number of subbands and block size\n",
        "CHUNK_SIZE = N                 # Blocksize\n",
        "FORMAT = pyaudio.paInt16       # Conversion format for PyAudio stream\n",
        "CHANNELS = 1                   # Audio Channels\n",
        "RATE = 32000                   # Sampling Rate in Hz\n",
        "FFT_LEN = N                    # FFT Length\n",
        "\n",
        "rows=500\n",
        "cols=CHUNK_SIZE\n",
        "fftlen=cols\n",
        "frame=0.0*np.ones((rows,cols,3));"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mHq_HyGEL1jq"
      },
      "outputs": [],
      "source": [
        "#The D(z) matrix:\n",
        "def Dmatrix(samples):\n",
        "    #implementation of the delay matrix D(z)\n",
        "    #Delay elements:\n",
        "    out=np.zeros(N)\n",
        "    out[0:int(N/2)]=Dmatrix.z\n",
        "    Dmatrix.z=samples[0:int(N/2)]\n",
        "    out[int(N/2):N]=samples[int(N/2):N]\n",
        "    return out\n",
        "\n",
        "Dmatrix.z=np.zeros(int(N/2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f3OIQrHOL1jq"
      },
      "outputs": [],
      "source": [
        "#The inverse D(z) matrix:\n",
        "def Dmatrixinv(samples):\n",
        "    #implementation of the delay matrix D(z)\n",
        "    #Delay elements:\n",
        "    out=np.zeros(N)\n",
        "    out[int(N/2):N]=Dmatrixinv.z\n",
        "    Dmatrixinv.z=samples[int(N/2):N]\n",
        "    out[0:int(N/2)]=samples[0:int(N/2)]\n",
        "    return out\n",
        "\n",
        "Dmatrixinv.z=np.zeros(int(N/2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KEKZD8ZYL1jq"
      },
      "outputs": [],
      "source": [
        "#The F Matrix:\n",
        "fcoeff=np.sin(np.pi/(2*N)*(np.arange(0,2*N)+0.5))\n",
        "Fmatrix=np.zeros((N,N))\n",
        "Fmatrix[0:int(N/2),0:int(N/2)]=np.fliplr(np.diag(fcoeff[0:int(N/2)]))\n",
        "Fmatrix[int(N/2):N,0:int(N/2)]=np.diag(fcoeff[int(N/2):N])\n",
        "Fmatrix[0:int(N/2),int(N/2):N]=np.diag(fcoeff[N:int(N+N/2)])\n",
        "Fmatrix[int(N/2):N,int(N/2):N]=-np.fliplr(np.diag(fcoeff[int(N+N/2):(2*N)]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KPGW7D4kL1jq"
      },
      "outputs": [],
      "source": [
        "#The inverse F matrix:\n",
        "Finv=np.linalg.inv(Fmatrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f1lhIpR4L1jq"
      },
      "outputs": [],
      "source": [
        "#The DCT4 transform:\n",
        "def DCT4(samples):\n",
        "    #use a DCT3 to implement a DCT4:\n",
        "    samplesup=np.zeros(2*N)\n",
        "    #upsample signal:\n",
        "    samplesup[1::2]=samples\n",
        "    y=spfft.dct(samplesup,type=3)/2\n",
        "    return y[0:N]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fE3Nr0OIL1jq"
      },
      "outputs": [],
      "source": [
        "#The complete MDCT, Analysis:\n",
        "def MDCT(samples):\n",
        "    y=np.dot(samples,Fmatrix)\n",
        "    y=Dmatrix(y)\n",
        "    y=DCT4(y)\n",
        "    return y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nMavqRi0L1jq"
      },
      "outputs": [],
      "source": [
        "#The inverse MDCT, synthesis:\n",
        "def MDCTinv(y):\n",
        "    #inverse DCT4 is identical to DCT4:\n",
        "    x=DCT4(y)*2/N\n",
        "    #inverse D(z) matrix\n",
        "    x=Dmatrixinv(x)\n",
        "    #inverse F matrix\n",
        "    x=np.dot(x,Finv)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "71_3RA7FL1jq"
      },
      "outputs": [],
      "source": [
        "# GUI\n",
        "toggle_run = ToggleButton(description='Stop')\n",
        "button_start= Button(description='Start')\n",
        "\n",
        "def start_button(button_start):\n",
        "    thread.start()\n",
        "    button_start.disabled=True\n",
        "button_start.on_click(start_button)\n",
        "\n",
        "\n",
        "def on_click_toggle_run(change):\n",
        "    if change['new']==False:\n",
        "        stream.stop_stream()\n",
        "        stream.close()\n",
        "        p.terminate()\n",
        "        cv2.destroyAllWindows()\n",
        "        plt.close()\n",
        "toggle_run.observe(on_click_toggle_run, 'value')\n",
        "\n",
        "box_buttons = HBox([button_start,toggle_run])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7RGo0rnaL1jq"
      },
      "outputs": [],
      "source": [
        "# Function to Plot MDCT\n",
        "\n",
        "def run_mdct(toggle_run):\n",
        "    while(True):\n",
        "        if toggle_run.value==True:\n",
        "            break\n",
        "\n",
        "        #Reading from audio input stream into data with block length \"CHUNK\":\n",
        "        data = stream.read(CHUNK_SIZE)\n",
        "        #Convert from stream of bytes to a list of short integers (2 bytes here) in \"samples\":\n",
        "        #shorts = (struct.unpack( \"128h\", data ))\n",
        "        shorts = (struct.unpack( 'h' * CHUNK_SIZE, data ));\n",
        "        samples=np.array(list(shorts),dtype=float);\n",
        "\n",
        "        #shift \"frame\" 1 up:\n",
        "        frame[0:(rows-1),:]=frame[1:rows,:];\n",
        "        #compute magnitude of 1D FFT of sound\n",
        "        #with suitable normalization for the display:\n",
        "        #frame=np.abs(np.ffqt.fft2(frame[:,:,1]/255.0))/512.0\n",
        "        #write magnitude spectrum in lowes row of \"frame\":\n",
        "        #R=0.25*np.log((np.abs(np.fft.fft(samples[0:fftlen])[0:(fftlen/2)]/np.sqrt(fftlen))+1))/np.log(10.0)\n",
        "\n",
        "        #This is the FFT of the input:\n",
        "        #y=np.fft.fft(samples[0:fftlen])\n",
        "        #This is the analysis MDCT of the input:\n",
        "        y=MDCT(samples[0:fftlen])\n",
        "\n",
        "        #yfilt is the processed subbands, processing goes here:\n",
        "        yfilt=y\n",
        "        #yfilt=np.zeros(N)\n",
        "        #yfilt[10:150]=y[10:150]\n",
        "        #yfilt[1]=y[1]*8\n",
        "        #yfilt[0:1024]=y[0:1024]\n",
        "\n",
        "        #Waterfall color mapping:\n",
        "        R=0.25*np.log((np.abs(yfilt/np.sqrt(fftlen))+1))/np.log(10.0)\n",
        "        #Red frame:\n",
        "        frame[rows-1,:,2]=R\n",
        "        #Green frame:\n",
        "        frame[rows-1,:,1]=np.abs(1-2*R)\n",
        "        #Blue frame:\n",
        "        frame[rows-1,:,0]=1.0-R\n",
        "        #frame[rows-1,:,0]=frame[rows-1,:,1]**3\n",
        "        # Display the resulting frame\n",
        "        cv2.imshow('frame',frame)\n",
        "\n",
        "        #Inverse FFT:\n",
        "        #xrek=np.real(np.fft.ifft(yfilt))\n",
        "        #Inverse/synthesis MDCT:\n",
        "        xrek=MDCTinv(yfilt).astype(int);\n",
        "        xrek=np.clip(xrek, -32000,32000)\n",
        "        #converting from short integers to a stream of bytes in \"data\":\n",
        "        #data=struct.pack('h' * len(samples), *samples);\n",
        "        data=struct.pack('h' * len(xrek), *xrek);\n",
        "        #Writing data back to audio output stream:\n",
        "        stream.write(data, CHUNK_SIZE)\n",
        "\n",
        "        #Keep window open until key 'q' is pressed:\n",
        "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "            break\n",
        "    # When everything done, release the capture\n",
        "    stream.stop_stream()\n",
        "    stream.close()\n",
        "    p.terminate()\n",
        "    cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UCs-Zj3cL1jq"
      },
      "outputs": [],
      "source": [
        "# Create a Thread for run_spectrogram function\n",
        "thread = threading.Thread(target=run_mdct, args=(toggle_run,))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bUfHkM67L1jq"
      },
      "outputs": [],
      "source": [
        "# Start Audio Stream\n",
        "# Create\n",
        "p = pyaudio.PyAudio()\n",
        "\n",
        "stream = p.open(format=FORMAT,\n",
        "                channels=CHANNELS,\n",
        "                rate=RATE,\n",
        "                input=True,\n",
        "                output=True,\n",
        "                frames_per_buffer=CHUNK_SIZE)\n",
        "\n",
        "input_data = stream.read(CHUNK_SIZE)\n",
        "samples = np.frombuffer(input_data,np.int16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3YMeTQ0dL1jq"
      },
      "outputs": [],
      "source": [
        "# Initialize Plot and Display GUI\n",
        "\n",
        "display(box_buttons)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kjx-Hz_EL1jq"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.8"
    },
    "livereveal": {
      "rise": {
        "height": "90%",
        "width": "90%"
      },
      "scroll": true,
      "theme": "beige",
      "transition": "zoom"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}